pub use gguf::gguf_file::{
    header_find_f32, header_find_string, header_find_string_array, header_find_usize, GGUFFile,
    GGUFTensor,
};
use half::f16;
use memmap2::{Mmap, MmapOptions};
use std::collections::BTreeMap;
use std::fmt::Debug;
use std::fs::File;
use std::rc::Rc;

mod gguf;
pub use gguf::GGMLType;
use gguf::{read_gguf_file, GGUFHeader};
use ymath::tensor::{IsTensor, MmapStore, Tensor, TensorTypes, VecStore, MATRIX, VECTOR};

#[derive(Debug)]
pub struct ModelFile<E = ()> {
    #[allow(dead_code)]
    _path: String,
    pub mmap: Rc<Mmap>,
    pub header: GGUFHeader,
    pub tensors: BTreeMap<String, GGUFTensor<E>>,
    pub tensor_data_offset: u64,
}

pub trait Tensorify<'a, T, SHAPE: IsTensor, U, MF>
where
    U: TensorTypes<T, SHAPE>,
{
    fn to_tensor(
        &self,
        mf: MF,
    ) -> Result<Tensor<'a, false, T, SHAPE, U>, Box<dyn std::error::Error>>;
}

// Macro generated by Claude
macro_rules! count {
    () => (0usize);
    ( $x:tt $(, $xs:tt)* ) => (1usize + count!($($xs)*));
}

macro_rules! check_dimensions {
    ($dims:expr, $($dim:ident),+) => {
        check_dimensions_inner!($dims, 0, $($dim),+)
    };
}

macro_rules! check_dimensions_inner {
    ($dims:expr, $index:expr, $dim:ident) => {
        $dims[$index] == $dim as u64
    };
    ($dims:expr, $index:expr, $dim:ident, $($rest:ident),+) => {
        $dims[$index] == $dim as u64 && check_dimensions_inner!($dims, $index + 1, $($rest),+)
    };
}

macro_rules! impl_tensorify_for_mmapstore_f32 {
    ($typ:path, $shape:ident, $($dim:ident),+) => {
        impl<'a, $(const $dim: usize),+> Tensorify<'a, f32, $shape<$($dim),+>, MmapStore<f32, f32>, &ModelFile>
            for GGUFTensor<()>
        {
            fn to_tensor(
                &self,
                model: &ModelFile,
            ) -> Result<Tensor<'a, false, f32, $shape<$($dim),+>, MmapStore<f32, f32>>, Box<dyn std::error::Error>> {
                let d = self.dimensions.len();
                if d != count!($($dim),+) || !check_dimensions!(self.dimensions, $($dim),+) {
                    return Err(anyhow::anyhow!("wrong dimension for tensor '{}'", &self.name).into());
                };
                let n_elem: usize = self.dimensions.iter().fold(1, |a, b| a * b) as usize;
                let mmap = &model.mmap;
                let tensor_data_offset = model.tensor_data_offset;
                let base_ptr = mmap.as_ptr();
                let data = unsafe { base_ptr.add((tensor_data_offset + self.relative_offset) as usize) };
                let slice = match self.tensor_type {
                    $typ => unsafe { std::slice::from_raw_parts(data as *const f32, n_elem) },
                    _ => return Err(anyhow::anyhow!("wrong type for tensor '{}'", &self.name).into()),
                };
                Ok(Tensor {
                    store: (Rc::clone(mmap), slice),
                })
            }
        }
    };
}

impl_tensorify_for_mmapstore_f32!(GGMLType::F32, VECTOR, D0);
impl_tensorify_for_mmapstore_f32!(GGMLType::F32, MATRIX, D0, D1);

macro_rules! impl_tensorify_for_mmapstore_f16 {
    ($typ:path, $shape:ident, $($dim:ident),+) => {
        impl<'a, $(const $dim: usize),+> Tensorify<'a, f32, $shape<$($dim),+>, MmapStore<f32, f16>, &ModelFile>
            for GGUFTensor<()>
        {
            fn to_tensor(
                &self,
                model: &ModelFile,
            ) -> Result<Tensor<'a, false, f32, $shape<$($dim),+>, MmapStore<f32, f16>>, Box<dyn std::error::Error>> {
                let d = self.dimensions.len();
                if d != count!($($dim),+) || !check_dimensions!(self.dimensions, $($dim),+) {
                    return Err(anyhow::anyhow!("wrong dimension for tensor '{}'", &self.name).into());
                };
                let n_elem: usize = self.dimensions.iter().fold(1, |a, b| a * b) as usize;
                let mmap = &model.mmap;
                let tensor_data_offset = model.tensor_data_offset;
                let base_ptr = mmap.as_ptr();
                let data = unsafe { base_ptr.add((tensor_data_offset + self.relative_offset) as usize) };
                let slice = match self.tensor_type {
                    $typ => unsafe { std::slice::from_raw_parts(data as *const f16, n_elem) },
                    _ => return Err(anyhow::anyhow!("wrong type for tensor '{}'", &self.name).into()),
                };
                Ok(Tensor {
                    store: (Rc::clone(mmap), slice),
                })
            }
        }
    };
}

impl_tensorify_for_mmapstore_f16!(GGMLType::F16, VECTOR, D0);
impl_tensorify_for_mmapstore_f16!(GGMLType::F16, MATRIX, D0, D1);

macro_rules! impl_tensorify_for_vecstore_f16 {
    ($typ:path, $shape:ident, $($dim:ident),+) => {
        impl<'a, $(const $dim: usize),+> Tensorify<'a, f32, $shape<$($dim),+>, VecStore<f32>, &ModelFile>
            for GGUFTensor<()>
        {
            fn to_tensor(
                &self,
                model: &ModelFile,
            ) -> Result<Tensor<'a, false, f32, $shape<$($dim),+>, VecStore<f32>>, Box<dyn std::error::Error>> {
                let d = self.dimensions.len();
                if d != count!($($dim),+) || !check_dimensions!(self.dimensions, $($dim),+) {
                    return Err(anyhow::anyhow!("wrong dimension for tensor '{}'", &self.name).into());
                };
                let n_elem: usize = self.dimensions.iter().fold(1, |a, b| a * b) as usize;
                let mmap = &model.mmap;
                let tensor_data_offset = model.tensor_data_offset;
                let base_ptr = mmap.as_ptr();
                let data = unsafe { base_ptr.add((tensor_data_offset + self.relative_offset) as usize) };
                let vec: Vec<f32> = match self.tensor_type {
                    GGMLType::F16 => unsafe { std::slice::from_raw_parts(data as *const f16, n_elem).iter().map(|&x| x.into()).collect() },
                    GGMLType::F32 => unsafe { std::slice::from_raw_parts(data as *const f32, n_elem).iter().map(|&x| x.into()).collect() },
                    _ => return Err(anyhow::anyhow!("wrong type for tensor '{}'", &self.name).into()),
                };
                Ok(Tensor {
                    store: vec,
                })
            }
        }
    };
}

impl_tensorify_for_vecstore_f16!(GGMLType::F16, VECTOR, D0);
impl_tensorify_for_vecstore_f16!(GGMLType::F16, MATRIX, D0, D1);

// Load a GGUF file
pub fn load_fast<'a>(
    path: &str,
) -> Result<(String, String, GGUFFile<()>), Box<dyn std::error::Error>> {
    let gguf = read_gguf_file(path.into(), 1_000_000)?;
    let arch = header_find_string(&gguf.header, "general.architecture")?;
    let name = header_find_string(&gguf.header, "general.name")?;
    Ok((arch.to_string(), name.to_string(), gguf))
}

pub fn load_build<'a>(
    path: &str,
    gguf: GGUFFile<()>,
) -> Result<ModelFile, Box<dyn std::error::Error>> {
    let file = File::open(path)?;
    let mmap = unsafe { MmapOptions::new().populate().map(&file)? };
    let mmap_rc = Rc::new(mmap);
    let tensor_data_offset = gguf.tensor_data_offset;

    Ok(ModelFile {
        mmap: mmap_rc,
        _path: path.to_string(),
        header: gguf.header,
        tensors: gguf.tensors,
        tensor_data_offset,
    })
}
